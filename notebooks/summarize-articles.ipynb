{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>image</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "      <th>likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-07</td>\n",
       "      <td>10 invenzioni geniali firmate Nikola Tesla</td>\n",
       "      <td>https://media-assets.wired.it/photos/63ad522d8...</td>\n",
       "      <td>https://www.wired.it/gallery/nikola-tesla-inve...</td>\n",
       "      <td>Quando sentiamo o leggiamo la parola Tesla ogg...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-07</td>\n",
       "      <td>17 novità a fumetti in uscita nel 2023</td>\n",
       "      <td>https://media-assets.wired.it/photos/63adb0f19...</td>\n",
       "      <td>https://www.wired.it/gallery/fumetti-2023-17-t...</td>\n",
       "      <td>Dopo un 2022 di grandi fumetti cosa ci attende...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-07</td>\n",
       "      <td>I gadget più assurdi visti alla fiera del sess...</td>\n",
       "      <td>https://media-assets.wired.it/photos/63b610c35...</td>\n",
       "      <td>https://www.wired.it/gallery/avn-expo-ecco-tut...</td>\n",
       "      <td>Ricordate quando i sex toy si ritagliarono uno...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-07</td>\n",
       "      <td>I consigli degli esperti per centrare (finalme...</td>\n",
       "      <td>https://media-assets.wired.it/photos/63b447c0f...</td>\n",
       "      <td>https://www.wired.it/article/obiettivi-2023-co...</td>\n",
       "      <td>Siamo di nuovo in quel periodo quello in cui u...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-07</td>\n",
       "      <td>Dobbiamo progettare le città tenendo conto del...</td>\n",
       "      <td>https://media-assets.wired.it/photos/63b45c70c...</td>\n",
       "      <td>https://www.wired.it/article/citta-progettazio...</td>\n",
       "      <td>Quando  stata lultima volta che camminando lun...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                              title  \\\n",
       "0  2023-01-07         10 invenzioni geniali firmate Nikola Tesla   \n",
       "1  2023-01-07             17 novità a fumetti in uscita nel 2023   \n",
       "2  2023-01-07  I gadget più assurdi visti alla fiera del sess...   \n",
       "3  2023-01-07  I consigli degli esperti per centrare (finalme...   \n",
       "4  2023-01-07  Dobbiamo progettare le città tenendo conto del...   \n",
       "\n",
       "                                               image  \\\n",
       "0  https://media-assets.wired.it/photos/63ad522d8...   \n",
       "1  https://media-assets.wired.it/photos/63adb0f19...   \n",
       "2  https://media-assets.wired.it/photos/63b610c35...   \n",
       "3  https://media-assets.wired.it/photos/63b447c0f...   \n",
       "4  https://media-assets.wired.it/photos/63b45c70c...   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://www.wired.it/gallery/nikola-tesla-inve...   \n",
       "1  https://www.wired.it/gallery/fumetti-2023-17-t...   \n",
       "2  https://www.wired.it/gallery/avn-expo-ecco-tut...   \n",
       "3  https://www.wired.it/article/obiettivi-2023-co...   \n",
       "4  https://www.wired.it/article/citta-progettazio...   \n",
       "\n",
       "                                                text  likes  \n",
       "0  Quando sentiamo o leggiamo la parola Tesla ogg...      0  \n",
       "1  Dopo un 2022 di grandi fumetti cosa ci attende...      0  \n",
       "2  Ricordate quando i sex toy si ritagliarono uno...      0  \n",
       "3  Siamo di nuovo in quel periodo quello in cui u...      0  \n",
       "4  Quando  stata lultima volta che camminando lun...      0  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/daily_news.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_summary(text):\n",
    "    # Usa il modello GPT-3 di OpenAI per fare il riassunto del testo\n",
    "    model_engine = \"text-davinci-003\"\n",
    "    prompt = (f\"Riassumi questo testo in 5 frasi (lingua italiana): {text} frasi: \\n \")\n",
    "    completions = openai.Completion.create(\n",
    "        engine=model_engine,\n",
    "        prompt=prompt,\n",
    "        max_tokens=300,\n",
    "        temperature=0.6,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0.0,\n",
    "        presence_penalty=1)\n",
    "    message = completions.choices[0].text\n",
    "    #summary = message.replace(\"Riassumi:\", \"\").strip()\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>image</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "      <th>likes</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-07</td>\n",
       "      <td>10 invenzioni geniali firmate Nikola Tesla</td>\n",
       "      <td>https://media-assets.wired.it/photos/63ad522d8...</td>\n",
       "      <td>https://www.wired.it/gallery/nikola-tesla-inve...</td>\n",
       "      <td>Quando sentiamo o leggiamo la parola Tesla ogg...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-07</td>\n",
       "      <td>17 novità a fumetti in uscita nel 2023</td>\n",
       "      <td>https://media-assets.wired.it/photos/63adb0f19...</td>\n",
       "      <td>https://www.wired.it/gallery/fumetti-2023-17-t...</td>\n",
       "      <td>Dopo un 2022 di grandi fumetti cosa ci attende...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-07</td>\n",
       "      <td>I gadget più assurdi visti alla fiera del sess...</td>\n",
       "      <td>https://media-assets.wired.it/photos/63b610c35...</td>\n",
       "      <td>https://www.wired.it/gallery/avn-expo-ecco-tut...</td>\n",
       "      <td>Ricordate quando i sex toy si ritagliarono uno...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-07</td>\n",
       "      <td>I consigli degli esperti per centrare (finalme...</td>\n",
       "      <td>https://media-assets.wired.it/photos/63b447c0f...</td>\n",
       "      <td>https://www.wired.it/article/obiettivi-2023-co...</td>\n",
       "      <td>Siamo di nuovo in quel periodo quello in cui u...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-07</td>\n",
       "      <td>Dobbiamo progettare le città tenendo conto del...</td>\n",
       "      <td>https://media-assets.wired.it/photos/63b45c70c...</td>\n",
       "      <td>https://www.wired.it/article/citta-progettazio...</td>\n",
       "      <td>Quando  stata lultima volta che camminando lun...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                              title  \\\n",
       "0  2023-01-07         10 invenzioni geniali firmate Nikola Tesla   \n",
       "1  2023-01-07             17 novità a fumetti in uscita nel 2023   \n",
       "2  2023-01-07  I gadget più assurdi visti alla fiera del sess...   \n",
       "3  2023-01-07  I consigli degli esperti per centrare (finalme...   \n",
       "4  2023-01-07  Dobbiamo progettare le città tenendo conto del...   \n",
       "\n",
       "                                               image  \\\n",
       "0  https://media-assets.wired.it/photos/63ad522d8...   \n",
       "1  https://media-assets.wired.it/photos/63adb0f19...   \n",
       "2  https://media-assets.wired.it/photos/63b610c35...   \n",
       "3  https://media-assets.wired.it/photos/63b447c0f...   \n",
       "4  https://media-assets.wired.it/photos/63b45c70c...   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://www.wired.it/gallery/nikola-tesla-inve...   \n",
       "1  https://www.wired.it/gallery/fumetti-2023-17-t...   \n",
       "2  https://www.wired.it/gallery/avn-expo-ecco-tut...   \n",
       "3  https://www.wired.it/article/obiettivi-2023-co...   \n",
       "4  https://www.wired.it/article/citta-progettazio...   \n",
       "\n",
       "                                                text  likes summary  \n",
       "0  Quando sentiamo o leggiamo la parola Tesla ogg...      0          \n",
       "1  Dopo un 2022 di grandi fumetti cosa ci attende...      0          \n",
       "2  Ricordate quando i sex toy si ritagliarono uno...      0          \n",
       "3  Siamo di nuovo in quel periodo quello in cui u...      0          \n",
       "4  Quando  stata lultima volta che camminando lun...      0          "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crea una nuova colonna \"summary\"\n",
    "df[\"summary\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text, max_tokens):\n",
    "    # Divide il testo in parole\n",
    "    words = text.split(\" \")\n",
    "    \n",
    "    # Conta il numero di parole\n",
    "    num_words = len(words)\n",
    "    \n",
    "    # Se il numero di parole è maggiore del numero massimo di token consentiti,\n",
    "    # estrai solo i primi max_tokens token\n",
    "    if num_words > max_tokens:\n",
    "        words = words[:max_tokens]\n",
    "    \n",
    "    # Ricomponi le parole in una stringa\n",
    "    summarized_text = \" \".join(words)\n",
    "    \n",
    "    return summarized_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividi il testo in parti da 500 token ciascuna\n",
    "text_parts = [df['text'][1][i:i+500] for i in range(0, len(df['text'][1]), 500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(text):\n",
    "    text_parts = [text[i:i+500] for i in range(0, len(text), 500)]\n",
    "    summary_parts = []\n",
    "    for part in text_parts:\n",
    "        # Crea il riassunto della parte corrente\n",
    "        summary = make_summary(part)\n",
    "        summary_parts.append(summary)\n",
    "    # Unisci le parti del riassunto in un unico riassunto\n",
    "    full_summary = ' '.join(summary_parts)\n",
    "    return full_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "This model's maximum context length is 4097 tokens, however you requested 5035 tokens (4735 in your prompt; 300 for the completion). Please reduce your prompt; or completion length.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39msummary\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(make_summary)\n",
      "File \u001b[0;32m~/miniconda/envs/mlp/lib/python3.8/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4668\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m~/miniconda/envs/mlp/lib/python3.8/site-packages/pandas/core/apply.py:1105\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m   1104\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1105\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/miniconda/envs/mlp/lib/python3.8/site-packages/pandas/core/apply.py:1156\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1154\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1155\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m-> 1156\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   1157\u001b[0m             values,\n\u001b[1;32m   1158\u001b[0m             f,\n\u001b[1;32m   1159\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   1160\u001b[0m         )\n\u001b[1;32m   1162\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1163\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1164\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1165\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/miniconda/envs/mlp/lib/python3.8/site-packages/pandas/_libs/lib.pyx:2918\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[85], line 5\u001b[0m, in \u001b[0;36mmake_summary\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      3\u001b[0m model_engine \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtext-davinci-003\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m prompt \u001b[39m=\u001b[39m (\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRiassumi questo testo in 5 frasi (lingua italiana): \u001b[39m\u001b[39m{\u001b[39;00mtext\u001b[39m}\u001b[39;00m\u001b[39m frasi: \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m completions \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m      6\u001b[0m     engine\u001b[39m=\u001b[39;49mmodel_engine,\n\u001b[1;32m      7\u001b[0m     prompt\u001b[39m=\u001b[39;49mprompt,\n\u001b[1;32m      8\u001b[0m     max_tokens\u001b[39m=\u001b[39;49m\u001b[39m300\u001b[39;49m,\n\u001b[1;32m      9\u001b[0m     temperature\u001b[39m=\u001b[39;49m\u001b[39m0.6\u001b[39;49m,\n\u001b[1;32m     10\u001b[0m     top_p\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     11\u001b[0m     frequency_penalty\u001b[39m=\u001b[39;49m\u001b[39m0.0\u001b[39;49m,\n\u001b[1;32m     12\u001b[0m     presence_penalty\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     13\u001b[0m message \u001b[39m=\u001b[39m completions\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtext\n\u001b[1;32m     14\u001b[0m \u001b[39m#summary = message.replace(\"Riassumi:\", \"\").strip()\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/mlp/lib/python3.8/site-packages/openai/api_resources/completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/miniconda/envs/mlp/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py:115\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    107\u001b[0m requestor \u001b[39m=\u001b[39m api_requestor\u001b[39m.\u001b[39mAPIRequestor(\n\u001b[1;32m    108\u001b[0m     api_key,\n\u001b[1;32m    109\u001b[0m     api_base\u001b[39m=\u001b[39mapi_base,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m     organization\u001b[39m=\u001b[39morganization,\n\u001b[1;32m    113\u001b[0m )\n\u001b[1;32m    114\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mclass_url(engine, api_type, api_version)\n\u001b[0;32m--> 115\u001b[0m response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    116\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    117\u001b[0m     url,\n\u001b[1;32m    118\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    119\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    120\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    121\u001b[0m     request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    122\u001b[0m     request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    123\u001b[0m )\n\u001b[1;32m    125\u001b[0m \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    126\u001b[0m     \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    127\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/miniconda/envs/mlp/lib/python3.8/site-packages/openai/api_requestor.py:181\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    161\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    162\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    169\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    170\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    171\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    172\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    173\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    179\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    180\u001b[0m     )\n\u001b[0;32m--> 181\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/miniconda/envs/mlp/lib/python3.8/site-packages/openai/api_requestor.py:396\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    389\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    390\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    391\u001b[0m         )\n\u001b[1;32m    392\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    393\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    394\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    395\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 396\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    397\u001b[0m             result\u001b[39m.\u001b[39;49mcontent, result\u001b[39m.\u001b[39;49mstatus_code, result\u001b[39m.\u001b[39;49mheaders, stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m    398\u001b[0m         ),\n\u001b[1;32m    399\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    400\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda/envs/mlp/lib/python3.8/site-packages/openai/api_requestor.py:429\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    427\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    428\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 429\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    430\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    431\u001b[0m     )\n\u001b[1;32m    432\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: This model's maximum context length is 4097 tokens, however you requested 5035 tokens (4735 in your prompt; 300 for the completion). Please reduce your prompt; or completion length."
     ]
    }
   ],
   "source": [
    "df['summary'] = df['text'].apply(make_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "\n",
    "# Carica il testo da riassumere in una variabile\n",
    "text = df['text'][0]\n",
    "\n",
    "# Pulisci il testo\n",
    "text = text.lower().replace(\",\", \"\").replace(\".\", \"\").replace(\"!\", \"\").replace(\"?\", \"\")\n",
    "\n",
    "# Crea una lista di token utilizzando la libreria nltk\n",
    "tokens = nltk.word_tokenize(text)\n",
    "\n",
    "# Carica il modello di embedding Word2Vec\n",
    "model = Word2Vec.load(\"path/to/model.bin\")\n",
    "\n",
    "# Crea gli embedding per ogni token utilizzando il modello Word2Vec\n",
    "embeddings = []\n",
    "for token in tokens:\n",
    "    if token in model.wv:\n",
    "        embeddings.append(model.wv[token])\n",
    "    else:\n",
    "        # Se il token non è presente nel modello, utilizza un vettore di embedding vuoto\n",
    "        embeddings.append(np.zeros(model.vector_size))\n",
    "\n",
    "# Calcola la similarità tra i vettori di embedding dei token utilizzando la funzione cosine_similarity di sklearn\n",
    "similarities = cosine_similarity(embeddings)\n",
    "\n",
    "# Identifica i token più importanti utilizzando l'algoritmo di clustering KMeans\n",
    "kmeans = KMeans(n_clusters=5)\n",
    "kmeans.fit(similarities)\n",
    "most_important_tokens = [tokens[i] for i in kmeans.cluster_centers_.argsort()[:,::-1][0][:5]]\n",
    "\n",
    "# Utilizza i token più importanti per creare il riassunto del testo\n",
    "summary = \"Riassunto:\\n\"\n",
    "for token in most_important_tokens:\n",
    "    summary += \"- \" + token + \"\\n\"\n",
    "\n",
    "print(summary)\"\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95fe2f621b02c291269f6f1de04399c71d5624912c164c733c30837729478179"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
