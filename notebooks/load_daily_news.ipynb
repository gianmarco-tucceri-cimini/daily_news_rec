{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set user agent\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.96 Safari/537.36\"} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIRED = 'https://www.wired.it'\n",
    "SOLE24 = 'https://www.ilsole24ore.com/'\n",
    "ANSA = 'https://www.ansa.it'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get pages\n",
    "wired = requests.get(WIRED, headers=headers)\n",
    "#sole24 = requests.get(SOLE24, headers=headers)\n",
    "#ansa = requests.get(ANSA, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the HTML content\n",
    "soup_wired = BeautifulSoup(wired.content, 'html.parser')\n",
    "#sole24_wired = BeautifulSoup(sole24.content, 'html.parser')\n",
    "#ansa_wired = BeautifulSoup(ansa.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea una lista vuota che conterrà i dati estratti\n",
    "data = []\n",
    "\n",
    "# Seleziona l'elemento\n",
    "articles = soup_wired.select(\"div[class^='SummaryItemWrapper-gcQMOo hHjGOU']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleziona tutti gli elementi\n",
    "elements = soup_wired.select(\"div[class^='SummaryItemWrapper']\")\n",
    "\n",
    "# Itera su ogni elemento\n",
    "for i in range(len(articles)):\n",
    "    # Estrai il titolo\n",
    "    title = articles[i].select_one(\"h3[class^='SummaryItemHedBase-dZZTtv gyXvAJ summary-item__hed']\").text\n",
    "    # Estrai immagine\n",
    "    img = articles[i].select_one(\"img\")['src']\n",
    "    # Estrai il link\n",
    "    link = articles[i].select_one(\"a[class='SummaryItemHedLink-cgaOJy cZNgnb summary-item-tracking__hed-link summary-item__hed-link']\")['href']\n",
    "\n",
    "    #estrai testo\n",
    "    article = WIRED + link\n",
    "    article_page = requests.get(article, headers=headers)\n",
    "    article_soup = BeautifulSoup(article_page.content, 'html.parser')\n",
    "    text = article_soup.select_one(\"div[class='GridItem-bwmuQH fQwjVg grid--item grid-layout__content']\").text\n",
    "\n",
    "    # Aggiungi i dati estratti alla lista\n",
    "    data.append({\n",
    "        'title': title,\n",
    "        'image': img,\n",
    "        'link': 'https://www.wired.it' + link,\n",
    "        'text': text\n",
    "    })\n",
    "\n",
    "# Crea un DataFrame Pandas a partire dalla lista di dati\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sole24 = requests.get(SOLE24, headers=headers)\n",
    "soup_sole24 = BeautifulSoup(sole24.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleziona l'elemento\n",
    "articles = soup_sole24.select(\"div[class^='col-']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sole = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Itera su ogni elemento\n",
    "for i in range(len(articles)-1):\n",
    "    # Estrai il titolo\n",
    "    title = articles[i].select_one(\"h3\").select_one(\"a\").text\n",
    "\n",
    "    # Estrai il link\n",
    "    link = articles[i].select_one('h3').select_one('a')['href']\n",
    "\n",
    "    #estraggo il testo\n",
    "    try:\n",
    "        article = SOLE24 + link\n",
    "        article_page = requests.get(article, headers=headers)\n",
    "        article_soup = BeautifulSoup(article_page.content, 'html.parser')\n",
    "        text = article_soup.select_one(\"div[class='col-lg-10']\").text\n",
    "        text = text.replace(\"Ascolta la versione audio dell'articolo\", \"\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Aggiungi i dati estratti alla lista\n",
    "    data_sole.append({\n",
    "        'title': title,\n",
    "        'image': 'https://www.ilsole24ore.com/static/img/ilsole24ore-o-2021.svg',\n",
    "        'link': 'https://www.ilsole24ore.com' + link,\n",
    "        'text': text\n",
    "    })\n",
    "\n",
    "# Crea un DataFrame Pandas a partire dalla lista di dati\n",
    "df_2 = pd.DataFrame(data_sole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ansa = requests.get(ANSA, headers=headers)\n",
    "soup_ansa = BeautifulSoup(ansa.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleziona l'elemento\n",
    "articles = soup_ansa.select(\"article[class^='news']\")\n",
    "\n",
    "# Crea una lista vuota che conterrà i dati estratti\n",
    "data_ansa = []\n",
    "\n",
    "# Itera su ogni elemento\n",
    "for i in range(11):\n",
    "    # Estrai il titolo\n",
    "    try:\n",
    "       title = articles[i].select_one(\"h3[class^='news-title area-primopiano']\").text\n",
    "    except:\n",
    "        pass\n",
    "    #estrai immagine\n",
    "    img = articles[i].select_one(\"h3[class^='news-title area-primopiano']\")['hp-img']\n",
    "\n",
    "    # Estrai il link\n",
    "    link = articles[i].select_one('h3').select_one('a')['href']\n",
    "\n",
    "    #estraggo il testo\n",
    "    article = ANSA + link\n",
    "    article_page = requests.get(article, headers=headers)\n",
    "    article_soup = BeautifulSoup(article_page.content, 'html.parser')\n",
    "    text = article_soup.select_one(\"div[class='news-txt']\").text\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "    # Aggiungi i dati estratti alla lista\n",
    "    data_ansa.append({\n",
    "        'title': title,\n",
    "        'image': 'https://www.ansa.it' + img,\n",
    "        'link': 'https://www.ansa.it' + link,\n",
    "        'text': text\n",
    "    })\n",
    "\n",
    "# Crea un DataFrame Pandas a partire dalla lista di dati\n",
    "df_3 = pd.DataFrame(data_ansa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "STAMPA = 'https://www.lastampa.it'\n",
    "page_stampa = requests.get(STAMPA, headers=headers)\n",
    "\n",
    "# Parse the HTML content\n",
    "soup_stampa = BeautifulSoup(page_stampa.content, 'html.parser')\n",
    "\n",
    "# Seleziona l'elemento\n",
    "articles = soup_stampa.select(\"article[class^='entry default']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea una lista vuota che conterrà i dati estratti\n",
    "data_stampa = []\n",
    "\n",
    "# Itera su ogni elemento\n",
    "for i in range(10):\n",
    "    # Estrai il titolo\n",
    "    title = articles[i].select_one('h2').text.strip()\n",
    "\n",
    "    # Estrai il link\n",
    "    link = articles[i].select_one('a')['href']\n",
    "\n",
    "    #estrai immagine\n",
    "    try:\n",
    "        img = articles[i].select_one(\"source\")['data-srcset']\n",
    "    except:\n",
    "        try:\n",
    "            img = articles[i].select_one(\"img\")['src']\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    #estraggo il testo\n",
    "    try:\n",
    "        article = link\n",
    "        article_page = requests.get(article, headers=headers)\n",
    "        article_soup = BeautifulSoup(article_page.content, 'html.parser')\n",
    "        text = article_soup.select_one(\"div[class='story__content']\").text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Aggiungi i dati estratti alla lista\n",
    "    data_stampa.append({\n",
    "        'title': title,\n",
    "        'image': img,\n",
    "        'link': link,\n",
    "        'text': text\n",
    "    })\n",
    "\n",
    "# Crea un DataFrame Pandas a partire dalla lista di dati\n",
    "df_4 = pd.DataFrame(data_stampa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "NATGEO = 'https://www.nationalgeographic.it'\n",
    "natgeo = requests.get(NATGEO, headers=headers)\n",
    "# Parse the HTML content\n",
    "natgeo_soup = BeautifulSoup(natgeo.content, 'html.parser')\n",
    "\n",
    "# Seleziona l'elemento\n",
    "articles = natgeo_soup.select(\"div[class^='css-2zs3eh']\")\n",
    "\n",
    "# Crea una lista vuota che conterrà i dati estratti\n",
    "data_natgeo = []\n",
    "\n",
    "# Itera su ogni elemento\n",
    "for i in range(len(articles)):\n",
    "    # Estrai il titolo\n",
    "    title = articles[i].select_one('a')['title']\n",
    "\n",
    "    # Estrai il link\n",
    "    link = articles[i].select_one('a')['href']\n",
    "\n",
    "    #estrai immagine\n",
    "    try:\n",
    "       img = articles[i].select_one('img')['src']\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    #estraggo il testo\n",
    "    try:\n",
    "        article = NATGEO + link\n",
    "        article_page = requests.get(article, headers=headers)\n",
    "        article_soup = BeautifulSoup(article_page.content, 'html.parser')\n",
    "        text = article_soup.select_one(\"div[class='ngart__main-col css-1b7gtbf']\").text\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Aggiungi i dati estratti alla lista\n",
    "    data_natgeo.append({\n",
    "        'title': title,\n",
    "        'image': img,\n",
    "        'link': NATGEO + link,\n",
    "        'text': text\n",
    "    })\n",
    "\n",
    "# Crea un DataFrame Pandas a partire dalla lista di dati\n",
    "df_5 = pd.DataFrame(data_natgeo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles2 = natgeo_soup.select(\"div[class^='css-ybrhvy']\")\n",
    "# Crea una lista vuota che conterrà i dati estratti\n",
    "data_natgeo2 = []\n",
    "\n",
    "# Itera su ogni elemento\n",
    "for i in range(len(articles2)):\n",
    "    # Estrai il titolo\n",
    "    try:\n",
    "       title2 = articles2[i].select_one('a')['title']\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Estrai il link\n",
    "    link2 = articles2[i].select_one('a')['href']\n",
    "\n",
    "    #estrai immagine\n",
    "    try:\n",
    "       img2 = articles2[i].select_one('img')['src']\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    #estraggo il testo\n",
    "    try:\n",
    "        article = NATGEO + link2\n",
    "        article_page = requests.get(article, headers=headers)\n",
    "        article_soup = BeautifulSoup(article_page.content, 'html.parser')\n",
    "        text2 = article_soup.select_one(\"div[class='ngart__main-col css-1b7gtbf']\").text\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Aggiungi i dati estratti alla lista\n",
    "    data_natgeo2.append({\n",
    "        'title': title2,\n",
    "        'image': img2,\n",
    "        'link': NATGEO + link2,\n",
    "        'text': text2\n",
    "    })\n",
    "\n",
    "# Crea un DataFrame Pandas a partire dalla lista di dati\n",
    "df_6 = pd.DataFrame(data_natgeo2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_news = pd.concat([df, df_2, df_3, df_4, df_5, df_6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_news = daily_news.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_news['date'] = datetime.datetime.today().strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_news.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>image</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-07</th>\n",
       "      <td>Guerra e razzismo: le tragiche storie dei migr...</td>\n",
       "      <td>https://static.nationalgeographic.it/files/sty...</td>\n",
       "      <td>https://www.nationalgeographic.it/storia-e-civ...</td>\n",
       "      <td>Amoakohene Ababio Williams, 26 anni, originari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-07</th>\n",
       "      <td>Anche gli animali sono vittime di guerra: il v...</td>\n",
       "      <td>https://static.nationalgeographic.it/files/sty...</td>\n",
       "      <td>https://www.nationalgeographic.it/animali/2022...</td>\n",
       "      <td>Più passa il tempo più la situazione degli ani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-07</th>\n",
       "      <td>Guerra in Ucraina: dobbiamo temere la minaccia...</td>\n",
       "      <td>https://static.nationalgeographic.it/files/sty...</td>\n",
       "      <td>https://www.nationalgeographic.it/storia-e-civ...</td>\n",
       "      <td>I negoziati tra Russia e Ucraina sono in corso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-07</th>\n",
       "      <td>Coronavirus: leggi tutti gli articoli</td>\n",
       "      <td>https://static.nationalgeographic.it/files/sty...</td>\n",
       "      <td>https://www.nationalgeographic.it/coronavirus</td>\n",
       "      <td>I negoziati tra Russia e Ucraina sono in corso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-07</th>\n",
       "      <td>Esistono persone resistenti al COVID‑19?</td>\n",
       "      <td>https://static.nationalgeographic.it/files/sty...</td>\n",
       "      <td>https://www.nationalgeographic.it/scienza/2022...</td>\n",
       "      <td>In Italia l'emergenza coronavirus è terminata ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        title  \\\n",
       "date                                                            \n",
       "2023-01-07  Guerra e razzismo: le tragiche storie dei migr...   \n",
       "2023-01-07  Anche gli animali sono vittime di guerra: il v...   \n",
       "2023-01-07  Guerra in Ucraina: dobbiamo temere la minaccia...   \n",
       "2023-01-07              Coronavirus: leggi tutti gli articoli   \n",
       "2023-01-07           Esistono persone resistenti al COVID‑19?   \n",
       "\n",
       "                                                        image  \\\n",
       "date                                                            \n",
       "2023-01-07  https://static.nationalgeographic.it/files/sty...   \n",
       "2023-01-07  https://static.nationalgeographic.it/files/sty...   \n",
       "2023-01-07  https://static.nationalgeographic.it/files/sty...   \n",
       "2023-01-07  https://static.nationalgeographic.it/files/sty...   \n",
       "2023-01-07  https://static.nationalgeographic.it/files/sty...   \n",
       "\n",
       "                                                         link  \\\n",
       "date                                                            \n",
       "2023-01-07  https://www.nationalgeographic.it/storia-e-civ...   \n",
       "2023-01-07  https://www.nationalgeographic.it/animali/2022...   \n",
       "2023-01-07  https://www.nationalgeographic.it/storia-e-civ...   \n",
       "2023-01-07      https://www.nationalgeographic.it/coronavirus   \n",
       "2023-01-07  https://www.nationalgeographic.it/scienza/2022...   \n",
       "\n",
       "                                                         text  \n",
       "date                                                           \n",
       "2023-01-07  Amoakohene Ababio Williams, 26 anni, originari...  \n",
       "2023-01-07  Più passa il tempo più la situazione degli ani...  \n",
       "2023-01-07  I negoziati tra Russia e Ucraina sono in corso...  \n",
       "2023-01-07  I negoziati tra Russia e Ucraina sono in corso...  \n",
       "2023-01-07  In Italia l'emergenza coronavirus è terminata ...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_news.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.replace(\"\\n\", \" \").replace(\"\\r\", \" \").replace('\"', \"\")\n",
    "    text = re.sub(r\"[^a-zA-Z0-9 ]\", \"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>image</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "      <th>likes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-07</th>\n",
       "      <td>10 invenzioni geniali firmate Nikola Tesla</td>\n",
       "      <td>https://media-assets.wired.it/photos/63ad522d8...</td>\n",
       "      <td>https://www.wired.it/gallery/nikola-tesla-inve...</td>\n",
       "      <td>Quando sentiamo o leggiamo la parola Tesla ogg...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-07</th>\n",
       "      <td>17 novità a fumetti in uscita nel 2023</td>\n",
       "      <td>https://media-assets.wired.it/photos/63adb0f19...</td>\n",
       "      <td>https://www.wired.it/gallery/fumetti-2023-17-t...</td>\n",
       "      <td>Dopo un 2022 di grandi fumetti cosa ci attende...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-07</th>\n",
       "      <td>I gadget più assurdi visti alla fiera del sess...</td>\n",
       "      <td>https://media-assets.wired.it/photos/63b610c35...</td>\n",
       "      <td>https://www.wired.it/gallery/avn-expo-ecco-tut...</td>\n",
       "      <td>Ricordate quando i sex toy si ritagliarono uno...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-07</th>\n",
       "      <td>I consigli degli esperti per centrare (finalme...</td>\n",
       "      <td>https://media-assets.wired.it/photos/63b447c0f...</td>\n",
       "      <td>https://www.wired.it/article/obiettivi-2023-co...</td>\n",
       "      <td>Siamo di nuovo in quel periodo quello in cui u...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-07</th>\n",
       "      <td>Dobbiamo progettare le città tenendo conto del...</td>\n",
       "      <td>https://media-assets.wired.it/photos/63b45c70c...</td>\n",
       "      <td>https://www.wired.it/article/citta-progettazio...</td>\n",
       "      <td>Quando  stata lultima volta che camminando lun...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        title  \\\n",
       "date                                                            \n",
       "2023-01-07         10 invenzioni geniali firmate Nikola Tesla   \n",
       "2023-01-07             17 novità a fumetti in uscita nel 2023   \n",
       "2023-01-07  I gadget più assurdi visti alla fiera del sess...   \n",
       "2023-01-07  I consigli degli esperti per centrare (finalme...   \n",
       "2023-01-07  Dobbiamo progettare le città tenendo conto del...   \n",
       "\n",
       "                                                        image  \\\n",
       "date                                                            \n",
       "2023-01-07  https://media-assets.wired.it/photos/63ad522d8...   \n",
       "2023-01-07  https://media-assets.wired.it/photos/63adb0f19...   \n",
       "2023-01-07  https://media-assets.wired.it/photos/63b610c35...   \n",
       "2023-01-07  https://media-assets.wired.it/photos/63b447c0f...   \n",
       "2023-01-07  https://media-assets.wired.it/photos/63b45c70c...   \n",
       "\n",
       "                                                         link  \\\n",
       "date                                                            \n",
       "2023-01-07  https://www.wired.it/gallery/nikola-tesla-inve...   \n",
       "2023-01-07  https://www.wired.it/gallery/fumetti-2023-17-t...   \n",
       "2023-01-07  https://www.wired.it/gallery/avn-expo-ecco-tut...   \n",
       "2023-01-07  https://www.wired.it/article/obiettivi-2023-co...   \n",
       "2023-01-07  https://www.wired.it/article/citta-progettazio...   \n",
       "\n",
       "                                                         text  likes  \n",
       "date                                                                  \n",
       "2023-01-07  Quando sentiamo o leggiamo la parola Tesla ogg...      0  \n",
       "2023-01-07  Dopo un 2022 di grandi fumetti cosa ci attende...      0  \n",
       "2023-01-07  Ricordate quando i sex toy si ritagliarono uno...      0  \n",
       "2023-01-07  Siamo di nuovo in quel periodo quello in cui u...      0  \n",
       "2023-01-07  Quando  stata lultima volta che camminando lun...      0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_news[\"text\"] = daily_news[\"text\"].apply(clean_text)\n",
    "daily_news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creo una colonna coi riassunti degli articoli\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "def make_summary(text):\n",
    "    # Usa il modello GPT-3 di OpenAI per fare il riassunto del testo\n",
    "    model_engine = \"text-davinci-003\"\n",
    "    prompt = (f\"Riassumi questo articolo di giornale, in lingua italiana, per una persona che non ha tempo di leggere l'intero articolo:\\n{text}\\n\"\n",
    "             f\"Scrivi 'riassumi' per iniziare\")\n",
    "    completions = openai.Completion.create(engine=model_engine, prompt=prompt, max_tokens=1024, n=1,stop=None,temperature=0.5)\n",
    "    message = completions.choices[0].text\n",
    "    summary = message.replace(\"Riassumi:\", \"\").strip()\n",
    "    return summary\n",
    "\n",
    "def split_text(text, max_tokens):\n",
    "    # Divide il testo in parole\n",
    "    words = text.split(\" \")\n",
    "    \n",
    "    # Conta il numero di parole\n",
    "    num_words = len(words)\n",
    "    \n",
    "    # Se il numero di parole è maggiore del numero massimo di token consentiti,\n",
    "    # estrai solo i primi max_tokens token\n",
    "    if num_words > max_tokens:\n",
    "        words = words[:max_tokens]\n",
    "    \n",
    "    # Ricomponi le parole in una stringa\n",
    "    summarized_text = \" \".join(words)\n",
    "    \n",
    "    return summarized_text\n",
    "\n",
    "# Crea una nuova colonna \"summary\"\n",
    "daily_news[\"summary\"] = \"\"\n",
    "\n",
    "# Per ogni riga del dataframe...\n",
    "for index, row in daily_news.iterrows():\n",
    "    # Recupera il testo dell'articolo\n",
    "    text = row[\"text\"]\n",
    "\n",
    "    split = split_text(text, 3645)\n",
    "\n",
    "    # Crea il riassunto dell'articolo\n",
    "    summary = make_summary(text)\n",
    "\n",
    "    # Aggiorna la riga del dataframe con il riassunto dell'articolo\n",
    "    daily_news.loc[index, \"summary\"] = summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_news['likes'] = 0\n",
    "daily_news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_news.to_csv('../data/daily_news.csv', quotechar='\"', quoting=csv.QUOTE_ALL, mode='a', header=False,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95fe2f621b02c291269f6f1de04399c71d5624912c164c733c30837729478179"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
