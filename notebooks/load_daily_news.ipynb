{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "\n",
    "import csv\n",
    "\n",
    "import openai\n",
    "\n",
    "from datetime import date, datetime\n",
    "\n",
    "import time\n",
    "\n",
    "from gtts import gTTS\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set user agent\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.96 Safari/537.36\"} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIRED = 'https://www.wired.it'\n",
    "SOLE24 = 'https://www.ilsole24ore.com/'\n",
    "ANSA = 'https://www.ansa.it'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get pages\n",
    "wired = requests.get(WIRED, headers=headers)\n",
    "#sole24 = requests.get(SOLE24, headers=headers)\n",
    "#ansa = requests.get(ANSA, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the HTML content\n",
    "soup_wired = BeautifulSoup(wired.content, 'html.parser')\n",
    "#sole24_wired = BeautifulSoup(sole24.content, 'html.parser')\n",
    "#ansa_wired = BeautifulSoup(ansa.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea una lista vuota che conterrà i dati estratti\n",
    "data = []\n",
    "\n",
    "# Seleziona l'elemento\n",
    "articles = soup_wired.select(\"div[class^='SummaryItemWrapper-gcQMOo hHjGOU']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleziona tutti gli elementi\n",
    "elements = soup_wired.select(\"div[class^='SummaryItemWrapper']\")\n",
    "\n",
    "# Itera su ogni elemento\n",
    "for i in range(len(articles)):\n",
    "    # Estrai il titolo\n",
    "    title = articles[i].select_one(\"h3[class^='SummaryItemHedBase-dZZTtv gyXvAJ summary-item__hed']\").text\n",
    "    # Estrai immagine\n",
    "    img = articles[i].select_one(\"img\")['src']\n",
    "    # Estrai il link\n",
    "    link = articles[i].select_one(\"a[class='SummaryItemHedLink-cgaOJy cZNgnb summary-item-tracking__hed-link summary-item__hed-link']\")['href']\n",
    "\n",
    "    #estrai testo\n",
    "    article = WIRED + link\n",
    "    article_page = requests.get(article, headers=headers)\n",
    "    article_soup = BeautifulSoup(article_page.content, 'html.parser')\n",
    "    text = article_soup.select_one(\"div[class='GridItem-bwmuQH fQwjVg grid--item grid-layout__content']\").text\n",
    "\n",
    "    # Aggiungi i dati estratti alla lista\n",
    "    data.append({\n",
    "        'title': title,\n",
    "        'image': img,\n",
    "        'link': 'https://www.wired.it' + link,\n",
    "        'text': text\n",
    "    })\n",
    "\n",
    "# Crea un DataFrame Pandas a partire dalla lista di dati\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['logo'] = 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/95/Wired_logo.svg/1200px-Wired_logo.svg.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sole24 = requests.get(SOLE24, headers=headers)\n",
    "soup_sole24 = BeautifulSoup(sole24.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleziona l'elemento\n",
    "articles = soup_sole24.select(\"div[class^='col-']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sole = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Itera su ogni elemento\n",
    "for i in range(len(articles)-1):\n",
    "    # Estrai il titolo\n",
    "    title = articles[i].select_one(\"h3\").select_one(\"a\").text\n",
    "\n",
    "    # Estrai il link\n",
    "    link = articles[i].select_one('h3').select_one('a')['href']\n",
    "\n",
    "    #estraggo il testo\n",
    "    try:\n",
    "        article = SOLE24 + link\n",
    "        article_page = requests.get(article, headers=headers)\n",
    "        article_soup = BeautifulSoup(article_page.content, 'html.parser')\n",
    "        text = article_soup.select_one(\"div[class='col-lg-10']\").text\n",
    "        text = text.replace(\"Ascolta la versione audio dell'articolo\", \"\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Aggiungi i dati estratti alla lista\n",
    "    data_sole.append({\n",
    "        'title': title,\n",
    "        'image': 'https://www.ilsole24ore.com/static/img/ilsole24ore-o-2021.svg',\n",
    "        'link': 'https://www.ilsole24ore.com' + link,\n",
    "        'text': text\n",
    "    })\n",
    "\n",
    "# Crea un DataFrame Pandas a partire dalla lista di dati\n",
    "df_2 = pd.DataFrame(data_sole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['logo'] = 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3d/Il_Sole_24_Ore.svg/2560px-Il_Sole_24_Ore.svg.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ansa = requests.get(ANSA, headers=headers)\n",
    "soup_ansa = BeautifulSoup(ansa.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleziona l'elemento\n",
    "articles = soup_ansa.select(\"article[class^='news']\")\n",
    "\n",
    "# Crea una lista vuota che conterrà i dati estratti\n",
    "data_ansa = []\n",
    "\n",
    "# Itera su ogni elemento\n",
    "for i in range(11):\n",
    "    # Estrai il titolo\n",
    "    try:\n",
    "       title = articles[i].select_one(\"h3[class^='news-title area-primopiano']\").text\n",
    "    except:\n",
    "        pass\n",
    "    #estrai immagine\n",
    "    img = articles[i].select_one(\"h3[class^='news-title area-primopiano']\")['hp-img']\n",
    "\n",
    "    # Estrai il link\n",
    "    link = articles[i].select_one('h3').select_one('a')['href']\n",
    "\n",
    "    #estraggo il testo\n",
    "    article = ANSA + link\n",
    "    article_page = requests.get(article, headers=headers)\n",
    "    article_soup = BeautifulSoup(article_page.content, 'html.parser')\n",
    "    text = article_soup.select_one(\"div[class='news-txt']\").text\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "    # Aggiungi i dati estratti alla lista\n",
    "    data_ansa.append({\n",
    "        'title': title,\n",
    "        'image': 'https://www.ansa.it' + img,\n",
    "        'link': 'https://www.ansa.it' + link,\n",
    "        'text': text\n",
    "    })\n",
    "\n",
    "# Crea un DataFrame Pandas a partire dalla lista di dati\n",
    "df_3 = pd.DataFrame(data_ansa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3['logo'] = 'https://www.ansa.it/sito/img/logo_ansa_green_185x41.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "STAMPA = 'https://www.lastampa.it'\n",
    "page_stampa = requests.get(STAMPA, headers=headers)\n",
    "\n",
    "# Parse the HTML content\n",
    "soup_stampa = BeautifulSoup(page_stampa.content, 'html.parser')\n",
    "\n",
    "# Seleziona l'elemento\n",
    "articles = soup_stampa.select(\"article[class^='entry default']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea una lista vuota che conterrà i dati estratti\n",
    "data_stampa = []\n",
    "\n",
    "# Itera su ogni elemento\n",
    "for i in range(10):\n",
    "    # Estrai il titolo\n",
    "    title = articles[i].select_one('h2').text.strip()\n",
    "\n",
    "    # Estrai il link\n",
    "    link = articles[i].select_one('a')['href']\n",
    "\n",
    "    #estrai immagine\n",
    "    try:\n",
    "        img = articles[i].select_one(\"source\")['data-srcset']\n",
    "    except:\n",
    "        try:\n",
    "            img = articles[i].select_one(\"img\")['src']\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    #estraggo il testo\n",
    "    try:\n",
    "        article = link\n",
    "        article_page = requests.get(article, headers=headers)\n",
    "        article_soup = BeautifulSoup(article_page.content, 'html.parser')\n",
    "        text = article_soup.select_one(\"div[class='story__content']\").text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Aggiungi i dati estratti alla lista\n",
    "    data_stampa.append({\n",
    "        'title': title,\n",
    "        'image': img,\n",
    "        'link': link,\n",
    "        'text': text\n",
    "    })\n",
    "\n",
    "# Crea un DataFrame Pandas a partire dalla lista di dati\n",
    "df_4 = pd.DataFrame(data_stampa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4['logo'] = 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f6/La_Stampa.svg/2560px-La_Stampa.svg.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "NATGEO = 'https://www.nationalgeographic.it'\n",
    "natgeo = requests.get(NATGEO, headers=headers)\n",
    "# Parse the HTML content\n",
    "natgeo_soup = BeautifulSoup(natgeo.content, 'html.parser')\n",
    "\n",
    "# Seleziona l'elemento\n",
    "articles = natgeo_soup.select(\"div[class^='css-2zs3eh']\")\n",
    "\n",
    "# Crea una lista vuota che conterrà i dati estratti\n",
    "data_natgeo = []\n",
    "\n",
    "# Itera su ogni elemento\n",
    "for i in range(len(articles)):\n",
    "    # Estrai il titolo\n",
    "    title = articles[i].select_one('a')['title']\n",
    "\n",
    "    # Estrai il link\n",
    "    link = articles[i].select_one('a')['href']\n",
    "\n",
    "    #estrai immagine\n",
    "    try:\n",
    "       img = articles[i].select_one('img')['src']\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    #estraggo il testo\n",
    "    try:\n",
    "        article = NATGEO + link\n",
    "        article_page = requests.get(article, headers=headers)\n",
    "        article_soup = BeautifulSoup(article_page.content, 'html.parser')\n",
    "        text = article_soup.select_one(\"div[class='ngart__main-col css-1b7gtbf']\").text\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Aggiungi i dati estratti alla lista\n",
    "    data_natgeo.append({\n",
    "        'title': title,\n",
    "        'image': img,\n",
    "        'link': NATGEO + link,\n",
    "        'text': text\n",
    "    })\n",
    "\n",
    "# Crea un DataFrame Pandas a partire dalla lista di dati\n",
    "df_5 = pd.DataFrame(data_natgeo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5['logo'] = 'https://logos-download.com/wp-content/uploads/2016/07/National_Geographic_logo.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles2 = natgeo_soup.select(\"div[class^='css-ybrhvy']\")\n",
    "# Crea una lista vuota che conterrà i dati estratti\n",
    "data_natgeo2 = []\n",
    "\n",
    "# Itera su ogni elemento\n",
    "for i in range(len(articles2)):\n",
    "    # Estrai il titolo\n",
    "    try:\n",
    "       title2 = articles2[i].select_one('a')['title']\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Estrai il link\n",
    "    link2 = articles2[i].select_one('a')['href']\n",
    "\n",
    "    #estrai immagine\n",
    "    try:\n",
    "       img2 = articles2[i].select_one('img')['src']\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    #estraggo il testo\n",
    "    try:\n",
    "        article = NATGEO + link2\n",
    "        article_page = requests.get(article, headers=headers)\n",
    "        article_soup = BeautifulSoup(article_page.content, 'html.parser')\n",
    "        text2 = article_soup.select_one(\"div[class='ngart__main-col css-1b7gtbf']\").text\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Aggiungi i dati estratti alla lista\n",
    "    data_natgeo2.append({\n",
    "        'title': title2,\n",
    "        'image': img2,\n",
    "        'link': NATGEO + link2,\n",
    "        'text': text2\n",
    "    })\n",
    "\n",
    "# Crea un DataFrame Pandas a partire dalla lista di dati\n",
    "df_6 = pd.DataFrame(data_natgeo2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_6['logo'] = 'https://logos-download.com/wp-content/uploads/2016/07/National_Geographic_logo.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>image</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "      <th>logo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cosa sono e come funzionano gli NFT?</td>\n",
       "      <td>https://static.nationalgeographic.it/files/sty...</td>\n",
       "      <td>https://www.nationalgeographic.it/scienza/2023...</td>\n",
       "      <td>Negli ultimi anni ha preso piede un nuovo form...</td>\n",
       "      <td>https://logos-download.com/wp-content/uploads/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Perché il \"turismo olfattivo\" è la nuova tende...</td>\n",
       "      <td>https://static.nationalgeographic.it/files/sty...</td>\n",
       "      <td>https://www.nationalgeographic.it/viaggi/2023/...</td>\n",
       "      <td>Una decina di viaggiatori si radunano attorno ...</td>\n",
       "      <td>https://logos-download.com/wp-content/uploads/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Avatar: La Via dell'Acqua\": James Cameron rac...</td>\n",
       "      <td>https://static.nationalgeographic.it/files/sty...</td>\n",
       "      <td>https://www.nationalgeographic.it/scienza/2022...</td>\n",
       "      <td>\"Avatar: La Via dell’Acqua\", sequel del lungom...</td>\n",
       "      <td>https://logos-download.com/wp-content/uploads/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Avatar: La Via dell'Acqua\": James Cameron rac...</td>\n",
       "      <td>https://static.nationalgeographic.it/files/sty...</td>\n",
       "      <td>https://www.nationalgeographic.it/wildlife</td>\n",
       "      <td>\"Avatar: La Via dell’Acqua\", sequel del lungom...</td>\n",
       "      <td>https://logos-download.com/wp-content/uploads/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Avatar: La Via dell'Acqua\": James Cameron rac...</td>\n",
       "      <td>https://static.nationalgeographic.it/files/sty...</td>\n",
       "      <td>https://www.nationalgeographic.it/viaggi</td>\n",
       "      <td>\"Avatar: La Via dell’Acqua\", sequel del lungom...</td>\n",
       "      <td>https://logos-download.com/wp-content/uploads/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0              Cosa sono e come funzionano gli NFT?    \n",
       "1  Perché il \"turismo olfattivo\" è la nuova tende...   \n",
       "2  \"Avatar: La Via dell'Acqua\": James Cameron rac...   \n",
       "3  \"Avatar: La Via dell'Acqua\": James Cameron rac...   \n",
       "4  \"Avatar: La Via dell'Acqua\": James Cameron rac...   \n",
       "\n",
       "                                               image  \\\n",
       "0  https://static.nationalgeographic.it/files/sty...   \n",
       "1  https://static.nationalgeographic.it/files/sty...   \n",
       "2  https://static.nationalgeographic.it/files/sty...   \n",
       "3  https://static.nationalgeographic.it/files/sty...   \n",
       "4  https://static.nationalgeographic.it/files/sty...   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://www.nationalgeographic.it/scienza/2023...   \n",
       "1  https://www.nationalgeographic.it/viaggi/2023/...   \n",
       "2  https://www.nationalgeographic.it/scienza/2022...   \n",
       "3         https://www.nationalgeographic.it/wildlife   \n",
       "4           https://www.nationalgeographic.it/viaggi   \n",
       "\n",
       "                                                text  \\\n",
       "0  Negli ultimi anni ha preso piede un nuovo form...   \n",
       "1  Una decina di viaggiatori si radunano attorno ...   \n",
       "2  \"Avatar: La Via dell’Acqua\", sequel del lungom...   \n",
       "3  \"Avatar: La Via dell’Acqua\", sequel del lungom...   \n",
       "4  \"Avatar: La Via dell’Acqua\", sequel del lungom...   \n",
       "\n",
       "                                                logo  \n",
       "0  https://logos-download.com/wp-content/uploads/...  \n",
       "1  https://logos-download.com/wp-content/uploads/...  \n",
       "2  https://logos-download.com/wp-content/uploads/...  \n",
       "3  https://logos-download.com/wp-content/uploads/...  \n",
       "4  https://logos-download.com/wp-content/uploads/...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORBES = 'https://forbes.it'\n",
    "\n",
    "forbes = requests.get(FORBES, headers=headers)\n",
    "forbes_soup = BeautifulSoup(forbes.content, 'html.parser')\n",
    "articles = forbes_soup.select(\"article\")\n",
    "\n",
    "# Crea una lista vuota che conterrà i dati estratti\n",
    "data_forbes = []\n",
    "\n",
    "# Itera su ogni elemento\n",
    "for i in range(10):\n",
    "    # Estrai il titolo\n",
    "    try:\n",
    "        title = articles[i].select_one(\"div[class^='forbes-title']\").text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Estrai il link\n",
    "    try:\n",
    "        link = articles[i].select_one('a')['href']\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    #estraggo il testo e immagine\n",
    "    try:\n",
    "        article = link\n",
    "        article_page = requests.get(article, headers=headers)\n",
    "        article_soup = BeautifulSoup(article_page.content, 'html.parser')\n",
    "        text = article_soup.select_one(\"div[class='entry-content my-3']\").text.strip()\n",
    "        img = article_soup.select_one(\"div[class^='post-thumbnail']\").select_one('img')['src'] \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Aggiungi i dati estratti alla lista\n",
    "    data_forbes.append({\n",
    "        'title': title,\n",
    "        'image': img,\n",
    "        'link': link,\n",
    "        'text': text\n",
    "    })\n",
    "    # Mette in pausa la funzione per 5 secondi\n",
    "    time.sleep(5)\n",
    "\n",
    "# Crea un DataFrame Pandas a partire dalla lista di dati\n",
    "df_7 = pd.DataFrame(data_forbes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_7['logo'] = 'https://forbes.it/wp-content/themes/forbes_theme_2021/images/forbes-logo-black.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIMES = 'https://www.limesonline.com'\n",
    "limes = requests.get(LIMES, headers=headers)\n",
    "limes_soup = BeautifulSoup(limes.content, 'html.parser')\n",
    "articles = limes_soup.select(\"article\")\n",
    "limes_data = []\n",
    "\n",
    "# Itera su ogni elemento\n",
    "for i in range(5):\n",
    "    # Estrai il titolo\n",
    "    title = articles[i].select_one(\"h2[class^='post-title']\").text\n",
    "\n",
    "    # Estrai il link\n",
    "    link = articles[i].select_one(\"a\")['href']\n",
    "\n",
    "    #estrai immagine\n",
    "    img = articles[1].select_one(\"img\")['src']\n",
    "\n",
    "\n",
    "    # Aggiungi i dati estratti alla lista\n",
    "    limes_data.append({\n",
    "        'title': title,\n",
    "        \"image\": img,\n",
    "        'link': link,\n",
    "        'text': None\n",
    "    })\n",
    "\n",
    "# Crea un DataFrame Pandas a partire dalla lista di dati\n",
    "df_8 = pd.DataFrame(data)\n",
    "\n",
    "df_8['logo'] = 'https://cdn.gelestatic.it/limesonline/www/2015/03/new-logo-1200.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_news = pd.concat([df, df_2, df_3, df_4, df_5, df_6, df_7, df_8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_news = daily_news.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_news['date'] = datetime.today().strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_news.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di duplicati: 0\n"
     ]
    }
   ],
   "source": [
    "# Verifica se ci sono duplicati\n",
    "duplicates = df['title'].duplicated()\n",
    "\n",
    "# Conta il numero di duplicati\n",
    "num_duplicates = sum(duplicates)\n",
    "\n",
    "# Stampa il numero di duplicati\n",
    "print(\"Numero di duplicati:\", num_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.replace(\"\\n\", \" \").replace(\"\\r\", \" \").replace('\"', \"\")\n",
    "    text = re.sub(r\"[^a-zA-Z0-9 ]\", \"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>image</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "      <th>logo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-11</th>\n",
       "      <td>Internet bene comune: a 10 anni dalla morte, l...</td>\n",
       "      <td>https://media-assets.wired.it/photos/615c469a5...</td>\n",
       "      <td>https://www.wired.it/article/aaron-swartz-10-a...</td>\n",
       "      <td>Il suicidio di Aaron Swartz esattamente dieci ...</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-11</th>\n",
       "      <td>Perché l'impennata di Covid-19 in Cina non dev...</td>\n",
       "      <td>https://media-assets.wired.it/photos/63bd34d24...</td>\n",
       "      <td>https://www.wired.it/article/covid-19-ondata-c...</td>\n",
       "      <td>Dopo quasi tre anni di rigide restrizioni per ...</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-11</th>\n",
       "      <td>Cucinare con il gas è davvero dannoso per la s...</td>\n",
       "      <td>https://media-assets.wired.it/photos/63bd7e441...</td>\n",
       "      <td>https://www.wired.it/article/cucinare-gas-dann...</td>\n",
       "      <td>Nelle ultime ore in Italia ma anche in tutta E...</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-11</th>\n",
       "      <td>Le app malevole che si fingono ChatGPT</td>\n",
       "      <td>https://media-assets.wired.it/photos/63bd8fbcc...</td>\n",
       "      <td>https://www.wired.it/article/chatgpt-app-andro...</td>\n",
       "      <td>Come pi che preventivabile i cybercriminali st...</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-11</th>\n",
       "      <td>Cibo fresco per cani a domicilio, ecco i migli...</td>\n",
       "      <td>https://media-assets.wired.it/photos/63bbe147c...</td>\n",
       "      <td>https://www.wired.it/article/cibo-fresco-cani-...</td>\n",
       "      <td>Il cibo fresco per cani a domicilio  un nuovo ...</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        title  \\\n",
       "date                                                            \n",
       "2023-01-11  Internet bene comune: a 10 anni dalla morte, l...   \n",
       "2023-01-11  Perché l'impennata di Covid-19 in Cina non dev...   \n",
       "2023-01-11  Cucinare con il gas è davvero dannoso per la s...   \n",
       "2023-01-11             Le app malevole che si fingono ChatGPT   \n",
       "2023-01-11  Cibo fresco per cani a domicilio, ecco i migli...   \n",
       "\n",
       "                                                        image  \\\n",
       "date                                                            \n",
       "2023-01-11  https://media-assets.wired.it/photos/615c469a5...   \n",
       "2023-01-11  https://media-assets.wired.it/photos/63bd34d24...   \n",
       "2023-01-11  https://media-assets.wired.it/photos/63bd7e441...   \n",
       "2023-01-11  https://media-assets.wired.it/photos/63bd8fbcc...   \n",
       "2023-01-11  https://media-assets.wired.it/photos/63bbe147c...   \n",
       "\n",
       "                                                         link  \\\n",
       "date                                                            \n",
       "2023-01-11  https://www.wired.it/article/aaron-swartz-10-a...   \n",
       "2023-01-11  https://www.wired.it/article/covid-19-ondata-c...   \n",
       "2023-01-11  https://www.wired.it/article/cucinare-gas-dann...   \n",
       "2023-01-11  https://www.wired.it/article/chatgpt-app-andro...   \n",
       "2023-01-11  https://www.wired.it/article/cibo-fresco-cani-...   \n",
       "\n",
       "                                                         text  \\\n",
       "date                                                            \n",
       "2023-01-11  Il suicidio di Aaron Swartz esattamente dieci ...   \n",
       "2023-01-11  Dopo quasi tre anni di rigide restrizioni per ...   \n",
       "2023-01-11  Nelle ultime ore in Italia ma anche in tutta E...   \n",
       "2023-01-11  Come pi che preventivabile i cybercriminali st...   \n",
       "2023-01-11  Il cibo fresco per cani a domicilio  un nuovo ...   \n",
       "\n",
       "                                                         logo  \n",
       "date                                                           \n",
       "2023-01-11  https://upload.wikimedia.org/wikipedia/commons...  \n",
       "2023-01-11  https://upload.wikimedia.org/wikipedia/commons...  \n",
       "2023-01-11  https://upload.wikimedia.org/wikipedia/commons...  \n",
       "2023-01-11  https://upload.wikimedia.org/wikipedia/commons...  \n",
       "2023-01-11  https://upload.wikimedia.org/wikipedia/commons...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_news[\"text\"] = daily_news[\"text\"].apply(clean_text)\n",
    "daily_news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "Timeout",
     "evalue": "Request timed out",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda/envs/mlp/lib/python3.8/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda/envs/mlp/lib/python3.8/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m     httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    445\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m     \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m     \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m     \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/mlp/lib/python3.8/http/client.py:1348\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1348\u001b[0m     response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1349\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda/envs/mlp/lib/python3.8/http/client.py:316\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 316\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    317\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n",
      "File \u001b[0;32m~/miniconda/envs/mlp/lib/python3.8/http/client.py:277\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 277\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    278\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n",
      "File \u001b[0;32m~/miniconda/envs/mlp/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    670\u001b[0m \u001b[39mexcept\u001b[39;00m timeout:\n",
      "File \u001b[0;32m~/miniconda/envs/mlp/lib/python3.8/ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1239\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1240\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1241\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1242\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda/envs/mlp/lib/python3.8/ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1099\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1100\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mTimeoutError\u001b[0m: [Errno 60] Operation timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mReadTimeoutError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda/envs/mlp/lib/python3.8/site-packages/requests/adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 489\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    490\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    491\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    492\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    493\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    494\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    496\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    497\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    498\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    499\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    500\u001b[0m     )\n\u001b[1;32m    502\u001b[0m \u001b[39m# Send the request.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda/envs/mlp/lib/python3.8/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m     e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, e)\n\u001b[0;32m--> 787\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[1;32m    788\u001b[0m     method, url, error\u001b[39m=\u001b[39;49me, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[1;32m    789\u001b[0m )\n\u001b[1;32m    790\u001b[0m retries\u001b[39m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/miniconda/envs/mlp/lib/python3.8/site-packages/urllib3/util/retry.py:550\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[39mif\u001b[39;00m read \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_method_retryable(method):\n\u001b[0;32m--> 550\u001b[0m     \u001b[39mraise\u001b[39;00m six\u001b[39m.\u001b[39;49mreraise(\u001b[39mtype\u001b[39;49m(error), error, _stacktrace)\n\u001b[1;32m    551\u001b[0m \u001b[39melif\u001b[39;00m read \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda/envs/mlp/lib/python3.8/site-packages/urllib3/packages/six.py:770\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[39mraise\u001b[39;00m value\u001b[39m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m--> 770\u001b[0m     \u001b[39mraise\u001b[39;00m value\n\u001b[1;32m    771\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda/envs/mlp/lib/python3.8/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    704\u001b[0m     conn,\n\u001b[1;32m    705\u001b[0m     method,\n\u001b[1;32m    706\u001b[0m     url,\n\u001b[1;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    711\u001b[0m )\n\u001b[1;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/mlp/lib/python3.8/site-packages/urllib3/connectionpool.py:451\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 451\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_timeout(err\u001b[39m=\u001b[39;49me, url\u001b[39m=\u001b[39;49murl, timeout_value\u001b[39m=\u001b[39;49mread_timeout)\n\u001b[1;32m    452\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/mlp/lib/python3.8/site-packages/urllib3/connectionpool.py:357\u001b[0m, in \u001b[0;36mHTTPConnectionPool._raise_timeout\u001b[0;34m(self, err, url, timeout_value)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mtimed out\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(err) \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mdid not complete (read)\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(\n\u001b[1;32m    355\u001b[0m     err\n\u001b[1;32m    356\u001b[0m ):  \u001b[39m# Python < 2.7.4\u001b[39;00m\n\u001b[0;32m--> 357\u001b[0m     \u001b[39mraise\u001b[39;00m ReadTimeoutError(\n\u001b[1;32m    358\u001b[0m         \u001b[39mself\u001b[39m, url, \u001b[39m\"\u001b[39m\u001b[39mRead timed out. (read timeout=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m timeout_value\n\u001b[1;32m    359\u001b[0m     )\n",
      "\u001b[0;31mReadTimeoutError\u001b[0m: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda/envs/mlp/lib/python3.8/site-packages/openai/api_requestor.py:356\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 356\u001b[0m     result \u001b[39m=\u001b[39m _thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    357\u001b[0m         method,\n\u001b[1;32m    358\u001b[0m         abs_url,\n\u001b[1;32m    359\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    360\u001b[0m         data\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    361\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    362\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    363\u001b[0m         timeout\u001b[39m=\u001b[39;49mrequest_timeout \u001b[39mif\u001b[39;49;00m request_timeout \u001b[39melse\u001b[39;49;00m TIMEOUT_SECS,\n\u001b[1;32m    364\u001b[0m     )\n\u001b[1;32m    365\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mTimeout \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda/envs/mlp/lib/python3.8/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/miniconda/envs/mlp/lib/python3.8/site-packages/requests/sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/mlp/lib/python3.8/site-packages/requests/adapters.py:578\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(e, ReadTimeoutError):\n\u001b[0;32m--> 578\u001b[0m     \u001b[39mraise\u001b[39;00m ReadTimeout(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[1;32m    579\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(e, _InvalidHeader):\n",
      "\u001b[0;31mReadTimeout\u001b[0m: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTimeout\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m summary \u001b[39m=\u001b[39m query(daily_news[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m][i])\n\u001b[1;32m     31\u001b[0m summary \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(summary[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mvalues())\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39mdict_values([\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m])\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m daily_news[\u001b[39m'\u001b[39m\u001b[39msummary\u001b[39m\u001b[39m'\u001b[39m][i] \u001b[39m=\u001b[39m correct_text(summary)\n",
      "Cell \u001b[0;32mIn[36], line 17\u001b[0m, in \u001b[0;36mcorrect_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     15\u001b[0m model_engine \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtext-curie-001\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m prompt \u001b[39m=\u001b[39m (\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRielabora questo testo in italiano giornalistico corretto: \u001b[39m\u001b[39m{\u001b[39;00mtext\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m completions \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m     18\u001b[0m     engine\u001b[39m=\u001b[39;49mmodel_engine,\n\u001b[1;32m     19\u001b[0m     prompt\u001b[39m=\u001b[39;49mprompt,\n\u001b[1;32m     20\u001b[0m     max_tokens\u001b[39m=\u001b[39;49m\u001b[39m150\u001b[39;49m,\n\u001b[1;32m     21\u001b[0m     temperature\u001b[39m=\u001b[39;49m\u001b[39m0.3\u001b[39;49m,\n\u001b[1;32m     22\u001b[0m     top_p\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     23\u001b[0m     frequency_penalty\u001b[39m=\u001b[39;49m\u001b[39m0.0\u001b[39;49m,\n\u001b[1;32m     24\u001b[0m     presence_penalty\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     25\u001b[0m message \u001b[39m=\u001b[39m completions\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtext\n\u001b[1;32m     26\u001b[0m \u001b[39m#summary = message.replace(\"Riassumi:\", \"\").strip()\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/mlp/lib/python3.8/site-packages/openai/api_resources/completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/miniconda/envs/mlp/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py:115\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    107\u001b[0m requestor \u001b[39m=\u001b[39m api_requestor\u001b[39m.\u001b[39mAPIRequestor(\n\u001b[1;32m    108\u001b[0m     api_key,\n\u001b[1;32m    109\u001b[0m     api_base\u001b[39m=\u001b[39mapi_base,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m     organization\u001b[39m=\u001b[39morganization,\n\u001b[1;32m    113\u001b[0m )\n\u001b[1;32m    114\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mclass_url(engine, api_type, api_version)\n\u001b[0;32m--> 115\u001b[0m response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    116\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    117\u001b[0m     url,\n\u001b[1;32m    118\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    119\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    120\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    121\u001b[0m     request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    122\u001b[0m     request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    123\u001b[0m )\n\u001b[1;32m    125\u001b[0m \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    126\u001b[0m     \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    127\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/miniconda/envs/mlp/lib/python3.8/site-packages/openai/api_requestor.py:171\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    161\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    162\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    169\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    170\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m--> 171\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_raw(\n\u001b[1;32m    172\u001b[0m         method\u001b[39m.\u001b[39;49mlower(),\n\u001b[1;32m    173\u001b[0m         url,\n\u001b[1;32m    174\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    175\u001b[0m         supplied_headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    176\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    177\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    178\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    179\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    180\u001b[0m     )\n\u001b[1;32m    181\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response(result, stream)\n\u001b[1;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/miniconda/envs/mlp/lib/python3.8/site-packages/openai/api_requestor.py:366\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    356\u001b[0m     result \u001b[39m=\u001b[39m _thread_context\u001b[39m.\u001b[39msession\u001b[39m.\u001b[39mrequest(\n\u001b[1;32m    357\u001b[0m         method,\n\u001b[1;32m    358\u001b[0m         abs_url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    363\u001b[0m         timeout\u001b[39m=\u001b[39mrequest_timeout \u001b[39mif\u001b[39;00m request_timeout \u001b[39melse\u001b[39;00m TIMEOUT_SECS,\n\u001b[1;32m    364\u001b[0m     )\n\u001b[1;32m    365\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mTimeout \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 366\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mTimeout(\u001b[39m\"\u001b[39m\u001b[39mRequest timed out\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mRequestException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    368\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mAPIConnectionError(\u001b[39m\"\u001b[39m\u001b[39mError communicating with OpenAI\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[0;31mTimeout\u001b[0m: Request timed out"
     ]
    }
   ],
   "source": [
    "# Crea una nuova colonna \"summary\"\n",
    "daily_news[\"summary\"] = \"\"\n",
    "daily_news['likes'] = 0\n",
    "daily_news.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_news.to_csv('../data/daily_news.csv', quotechar='\"', quoting=csv.QUOTE_ALL, mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di duplicati: 0\n"
     ]
    }
   ],
   "source": [
    "#cancella duplicati\n",
    "df1 = pd.read_csv('../data/daily_news.csv', index_col='date')\n",
    "# Verifica se ci sono duplicati\n",
    "duplicates = df1['link'].duplicated()\n",
    "\n",
    "# Conta il numero di duplicati\n",
    "num_duplicates = sum(duplicates)\n",
    "\n",
    "# Stampa il numero di duplicati\n",
    "print(\"Numero di duplicati:\", num_duplicates)\n",
    "\n",
    "def remove_duplicates(df, date_column):\n",
    "    # Controlla se ci sono duplicati utilizzando la colonna data\n",
    "    duplicates = df.duplicated(subset=date_column, keep='first')\n",
    "    # Rimuovi i duplicati\n",
    "    df = df[~duplicates]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = remove_duplicates(df1, 'link')\n",
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df1.reset_index()\n",
    "df_oggi = df1.loc[df1['date'] == datetime.today().strftime(\"%Y-%m-%d\")]\n",
    "df_nan = df_oggi[df_oggi['summary'].isna()]\n",
    "df_nan = df_nan.set_index('date')\n",
    "len(df_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"df_nan = df_nan.drop(df_nan.index[0], axis=0)\n",
    "len(df_nan)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-69-7531e634b593>:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nan['summary'][i] = correct_text(summary)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'clean_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m     summary \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(summary[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mvalues())\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39mdict_values([\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m])\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m     df_nan[\u001b[39m'\u001b[39m\u001b[39msummary\u001b[39m\u001b[39m'\u001b[39m][i] \u001b[39m=\u001b[39m correct_text(summary)\n\u001b[0;32m---> 31\u001b[0m df_nan[\u001b[39m\"\u001b[39m\u001b[39msummary\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df_nan[\u001b[39m\"\u001b[39m\u001b[39msummary\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mapply(clean_text)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clean_text' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/facebook/bart-large-cnn\"\n",
    "headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "def query(payload):\n",
    "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "\treturn response.json()\n",
    "\n",
    "def correct_text(text):\n",
    "    # Usa il modello GPT-3 di OpenAI per fare il riassunto del testo\n",
    "    model_engine = \"text-curie-001\"\n",
    "    prompt = (f\"Rielabora questo testo in italiano giornalistico corretto: {text}\")\n",
    "    completions = openai.Completion.create(\n",
    "        engine=model_engine,\n",
    "        prompt=prompt,\n",
    "        max_tokens=150,\n",
    "        temperature=0.3,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0.0,\n",
    "        presence_penalty=1)\n",
    "    message = completions.choices[0].text\n",
    "    #summary = message.replace(\"Riassumi:\", \"\").strip()\n",
    "    return message\n",
    "\n",
    "for i in range(len(df_nan)):\n",
    "    summary = query(df_nan['text'][i])\n",
    "    summary = str(summary[0].values()).replace(\"dict_values(['\", \"\").replace(\"'])\", \"...\")\n",
    "    df_nan['summary'][i] = correct_text(summary)\n",
    "\n",
    "df_nan[\"summary\"] = df_nan[\"summary\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#genero audio con google-text-to-speech\n",
    "\n",
    "language = 'it'\n",
    "tld = 'es'\n",
    "path = '../data/audio/'\n",
    "\n",
    "def generate_audio(df_nan, df1):\n",
    "    for index, row in df_nan.iterrows():\n",
    "        text = row[\"summary\"]\n",
    "        filename = f\"audio_{index}.mp3\"\n",
    "        tts = gTTS(text=text, lang=language, tld=tld, slow=False)\n",
    "        filepath = tts.save(path + filename)\n",
    "        # Aggiorna il valore della colonna \"audio\" del dataframe\n",
    "        df1.loc[index, \"audio\"] = 'data/audio/' + filename\n",
    "\n",
    "generate_audio(daily_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nan.to_csv('../data/daily_news_summary.csv', quotechar='\"', quoting=csv.QUOTE_ALL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95fe2f621b02c291269f6f1de04399c71d5624912c164c733c30837729478179"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
